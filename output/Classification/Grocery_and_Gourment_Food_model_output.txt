Number of features: 23
Logistic Regression Model Results:
Using l1 Regularization
Score for training set
0.6982804585443881
Null score for training set
0.5025993068515062
Coeficents for training set:
Predicted Labels:
[1 0 0 ... 0 0 1]
Predicted probabilities for each label:
[[0.26761044 0.73238956]
 [0.53561829 0.46438171]
 [0.57128691 0.42871309]
 ...
 [0.84030172 0.15969828]
 [0.79519949 0.20480051]
 [0.20181606 0.79818394]]
Print accuracy score:
0.6983904828551435
Print roc_auc_score:
0.7554267315010371
Confusion matrix:
[[4113 2321]
 [1558 4869]]
Classification report:
             precision    recall  f1-score   support

          0       0.73      0.64      0.68      6434
          1       0.68      0.76      0.72      6427

avg / total       0.70      0.70      0.70     12861

Using l2 Regularization
Score for training set
0.6983137829912024
Null score for training set
0.5025993068515062
Coeficents for training set:
Predicted Labels:
[1 0 0 ... 0 0 1]
Predicted probabilities for each label:
[[0.26748722 0.73251278]
 [0.5357431  0.4642569 ]
 [0.57119095 0.42880905]
 ...
 [0.8402607  0.1597393 ]
 [0.79508199 0.20491801]
 [0.20172289 0.79827711]]
Print accuracy score:
0.6987015006609129
Print roc_auc_score:
0.755424385747511
Confusion matrix:
[[4114 2320]
 [1555 4872]]
Classification report:
             precision    recall  f1-score   support

          0       0.73      0.64      0.68      6434
          1       0.68      0.76      0.72      6427

avg / total       0.70      0.70      0.70     12861

Random Forest:
Feature Importantces for training set:
Predicted Labels:
[0 0 0 ... 1 0 1]
Predicted probabilities for each label:
[[0.55  0.45 ]
 [0.582 0.418]
 [0.812 0.188]
 ...
 [0.146 0.854]
 [0.784 0.216]
 [0.124 0.876]]
Out-of-bag score estimate:0.7214076246334311
Mean accuracy score: 0.7249047507969831
Confusion matrix:
[[4710 1724]
 [1814 4613]]

Predicted probabilities for each label:
[[0.5263831  0.4736169 ]
 [0.60880667 0.39119333]
 [0.91757846 0.08242153]
 ...
 [0.27141595 0.72858405]
 [0.71501046 0.28498954]
 [0.14880753 0.8511925 ]]
Accuracy: 73.37%